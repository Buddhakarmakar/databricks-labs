{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "533e4736-307e-4419-b987-3a017e8f5f24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "834e36e5-ad4d-4a5c-a087-6b66ca4ffb5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 1 - Creating a Job Using Lakeflow Jobs UI\n",
    "\n",
    "In this lesson, we will start by creating a job using a single notebook and exploring the Lakeflow Jobs UI.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this lesson, you should be able to:\n",
    "* Schedule a notebook task in a Databricks Workflow Job\n",
    "* Describe job scheduling options and differences between cluster types\n",
    "* Review Job Runs to track progress and see results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fcb682c-22fe-4822-91c7-5eabda78fcc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "\n",
    "Follow these steps to select the classic compute cluster:\n",
    "\n",
    "\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "\n",
    "2. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "\n",
    "   - Click **More** in the drop-down.\n",
    "\n",
    "   - In the **Attach to an existing compute resource** window, use the first drop-down to select your unique cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "\n",
    "2. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "\n",
    "3. Wait a few minutes for the cluster to start.\n",
    "\n",
    "4. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d46b9761-a118-4b64-a07d-d9ea25e22f30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## A. Classroom Setup\n",
    "\n",
    "Run the following cell to configure your working environment for this course. It will also set your default catalog to **dbacademy** and the schema to your specific schema name shown below using the `USE` statements.\n",
    "<br></br>\n",
    "\n",
    "\n",
    "```\n",
    "USE CATALOG dbacademy;\n",
    "USE SCHEMA dbacademy.<your unique schema name>;\n",
    "```\n",
    "\n",
    "**NOTE:** The `DA` object is only used in Databricks Academy courses and is not available outside of these courses. It will dynamically reference the information needed to run the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa133d16-ed98-482f-982d-b445805017ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<table style=\"width:100%\">\n",
       "            <tr>\n",
       "                <td style=\"white-space:nowrap; width:1em\">Course Catalog:</td>\n",
       "                <td><input type=\"text\" value=\"dbacademy\" style=\"width: 100%\"></td></tr>\n",
       "            <tr>\n",
       "                <td style=\"white-space:nowrap; width:1em\">Your Schema:</td>\n",
       "                <td><input type=\"text\" value=\"labuser11184542_1755240991\" style=\"width: 100%\"></td></tr></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ./Includes/Classroom-Setup-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37692fed-4134-480d-83da-12e9b329849d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## B. Explore Your Schema\n",
    "1. Expand the course catalog **dbacademy** on the left.\n",
    "\n",
    "2. Expand your unique schema name using the information from the above cell. Please remember your schema name.\n",
    "\n",
    "3. Notice that within your schema no tables exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de547116-55ad-425d-b513-becb004bd7d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## C. Generate Job Configuration\n",
    "\n",
    "1. Run the cell below to print out values you'll use to configure your job in subsequent steps. Make sure to specify the correct job name and notebooks.\n",
    "\n",
    "**NOTE:** The `DA.print_job_config` object is specific to the Databricks Academy course. It will output the necessary information to help you create the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0903ee99-04e5-471a-8543-a571bd2561d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<table style=\"width:100%\">\n",
       "            <tr>\n",
       "                <td style=\"white-space:nowrap; width:1em\">Job Name:</td>\n",
       "                <td><input type=\"text\" value=\"labuser11184542_1755240991_Lesson_01\" style=\"width: 100%\"></td></tr>\n",
       "            <tr>\n",
       "                <td style=\"white-space:nowrap; width:1em\">Notebook #1:</td>\n",
       "                <td><input type=\"text\" value=\"/Workspace/Users/labuser11184542_1755240991@vocareum.com/deploy-workloads-with-lakeflow-jobs-3.0.1/Deploy Workloads with Lakeflow Jobs/Task Notebooks/Lesson 1 Notebooks/1.01 - Create Simple Table\" style=\"width: 100%\"></td></tr></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DA.print_job_config(job_name_extension='Lesson_01', \n",
    "                    notebook_paths='/Task Notebooks/Lesson 1 Notebooks',\n",
    "                    notebooks=['1.01 - Create Simple Table'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d9122ee-0776-4fc3-9a83-eb013b7342f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## D. Configure Job with a Single Notebook Task\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "329ead7a-9a28-4d1b-aa2c-da584db81cbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### D1. View the Notebook\n",
    "1. Select the link to open the [./Task Notebooks/Lesson 1/1.01 - Create Simple Table]($./Task Notebooks/Lesson 1 Notebooks/1.01 - Create Simple Table) notebook. Examine the notebook and notice that it will create a simple table named **lesson1_workflow_users** in your specified schema.\n",
    "\n",
    "2. Close the tab after the code has been reviewed and return to this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac2b72d1-708f-4e83-870a-c046907f50d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### D2. Configure the Job\n",
    "When using the Jobs UI to orchestrate a workload with multiple tasks, you'll always begin by creating a job with a single task.\n",
    "\n",
    "Steps:\n",
    "1. Right click on the **Jobs and Pipelines** button on the sidebar and select *Open Link in New Tab*. \n",
    "\n",
    "2. Select the **Jobs & Pipeline** tab, and then click the **Create** button and **choose Job from the dropdown**.\n",
    "\n",
    "3. In the top-left of the screen, enter the **Job Name** provided above to add a name for the job (must use the job name specified above).\n",
    "\n",
    "4. Configure the task as specified below. You'll need the values provided in the cell output above for this step.\n",
    "\n",
    "| Setting | Instructions |\n",
    "|--|--|\n",
    "| Task name | Enter the task name **create_table** |\n",
    "| Type | Choose **Notebook** |\n",
    "| Source | Choose **Workspace** |\n",
    "| Path | Use the navigator to specify the **Notebook #1** path above (**1.01 - Create Simple Table**) |\n",
    "| Compute | From the dropdown menu, select a **Serverless** cluster (We will be using Serverless clusters for jobs in this course. You can also specify a different cluster if required outside of this course) |\n",
    "| Create task | Click **Create task** |\n",
    "|Performance optimized mode (in Job Detail) | **Turn on**|\n",
    "\n",
    "**NOTE: Performance optimized mode** \n",
    "- **Performance-optimized mode**\n",
    "Fast, performant compute startup and execution speed.\n",
    "\n",
    "- **Standard mode**\n",
    "Disabling performance optimization gives you startup times similar to Classic infrastructure and reduces your cost.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**NOTE**: If you selected your all-purpose cluster, you may get a warning about how this will be billed as all-purpose compute. Production jobs should always be scheduled against new job clusters appropriately sized for the workload, as this is billed at a much lower rate.\n",
    "\n",
    "\n",
    "![Job Demo 1](./Includes/images/Lesson01_CreateJob.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b135a9ed-114a-4baa-934c-5fdeaa4f59a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## E. Run the Job\n",
    "\n",
    "1. In the upper-right corner, click the blue **Run now** button in the top right to start the job.\n",
    "\n",
    "**NOTE:** When you start the job run, you can click the link and view the run. However, let's look at another way you can view past, and current, job runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e973889c-fbe2-44d8-bbfe-218881a98e27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## F. Review the Job Run\n",
    "\n",
    "\n",
    "1. On the Job Details page, select the **Runs** tab in the top-left of the screen (you should currently be on the **Tasks** tab)\n",
    "\n",
    "2. Open the output details by clicking on the timestamp field under the **Start time** column\n",
    "    - If **the job is still running**, you will see the active state of the notebook with a **Status** of **`Pending`** or **`Running`** in the right side panel. \n",
    "    - If **the job has completed**, you will see the full execution of the notebook with a **Status** of **`Succeeded`** or **`Failed`** in the right side panel\n",
    "\n",
    "*Example*\n",
    "\n",
    "![Job Demo 1](./Includes/images/Lesson01_JobRun.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5222a506-48d8-45d5-a100-54665c4b74a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## G. View Your New Table\n",
    "1. From left-hand pane, select **Catalog**. Then drill down from **dbacademy** catalog.\n",
    "\n",
    "2. Expand your unique schema name.\n",
    "\n",
    "3. Notice that within your schema a table named **lesson1_workflow_users** was created from the job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60014e56-b499-45e7-bdba-82f7c7a9a1cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "[Lakeflow Jobs Documentation](https://docs.databricks.com/aws/en/jobs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a73592a-e71f-4179-a9d3-88a1cbc4e491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "&copy; 2025 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"blank\">Apache Software Foundation</a>.<br/>\n",
    "<br/><a href=\"https://databricks.com/privacy-policy\" target=\"blank\">Privacy Policy</a> | \n",
    "<a href=\"https://databricks.com/terms-of-use\" target=\"blank\">Terms of Use</a> | \n",
    "<a href=\"https://help.databricks.com/\" target=\"blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1 - Creating a Job Using Lakeflow Jobs UI",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}